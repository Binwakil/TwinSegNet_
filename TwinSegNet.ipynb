{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd53492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1: SETUP & IMPORTS\n",
    "\n",
    "# Core ML\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "import warnings\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# System and Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "IMG_SIZE = 128\n",
    "VOLUME_SLICES = 50\n",
    "VOLUME_START_AT = 22\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 5\n",
    "NUM_ROUNDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: BraTSDataset Loader\n",
    "\n",
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.patient_dirs = sorted(os.listdir(root_dir))\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_dirs[idx]\n",
    "        patient_path = os.path.join(self.root_dir, patient_id)\n",
    "\n",
    "        # Load MRI modalities\n",
    "        modalities = ['t1c', 't1n', 't2f', 't2w']\n",
    "        image_data = []\n",
    "        for mod in modalities:\n",
    "            image_path = os.path.join(patient_path, f\"{patient_id}-{mod}.nii\")\n",
    "            image = nib.load(image_path).get_fdata()\n",
    "            image_data.append(image)\n",
    "\n",
    "        image_np = np.stack(image_data, axis=0).astype(np.float32)\n",
    "        image_tensor = torch.tensor(image_np)\n",
    "\n",
    "        # Load segmentation label if in training mode\n",
    "# Inside __getitem__ in BraTSDataset\n",
    "        if self.train:\n",
    "            label_path = os.path.join(patient_path, f\"{patient_id}-seg.nii\")\n",
    "            label_np = nib.load(label_path).get_fdata().astype(np.uint8)\n",
    "\n",
    "            # üîß Remap labels: convert [0,1,2,4] ‚Üí [0,1,2,3] or compress to 3 classes\n",
    "            label_np[label_np == 4] = 3   # or label_np[label_np == 4] = 2 to merge 2+4 into one class\n",
    "\n",
    "            label_tensor = torch.tensor(label_np).unsqueeze(0)\n",
    "\n",
    "        else:\n",
    "            label_tensor = None  # inference only\n",
    "\n",
    "        # Apply TorchIO preprocessing\n",
    "        if self.transform:\n",
    "            subject_dict = {\"images\": tio.ScalarImage(tensor=image_tensor)}\n",
    "            if label_tensor is not None:\n",
    "                subject_dict[\"label\"] = tio.LabelMap(tensor=label_tensor)\n",
    "            subject = tio.Subject(**subject_dict)\n",
    "            transformed = self.transform(subject)\n",
    "            image_tensor = transformed.images.data\n",
    "            if label_tensor is not None:\n",
    "                label_tensor = transformed.label.data\n",
    "\n",
    "        return (image_tensor, label_tensor) if self.train else image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DataBank = \"Data\"\n",
    "Hospital1_Train = 'Data/2023GLI/TrainingData'\n",
    "Hospital1_Val = 'Data/2023GLI/ValidationData'\n",
    "Hospital2_Train = 'Data/2023MEN/TrainingData'\n",
    "Hospital2_Val = 'Data/2023MEN/ValidationData'\n",
    "Hospital3_Train = 'Data/2023MET/TrainingData'\n",
    "Hospital3_Val = 'Data/2023MET/ValidationData'\n",
    "Hospital4_Train = 'Data/2023PED/TrainingData'\n",
    "Hospital4_Val = 'Data/2023PED/ValidationData'\n",
    "Hospital5_Train = 'Data/2023SSA/TrainingData'\n",
    "Hospital5_Val = 'Data/2023SSA/ValidationData'\n",
    "Hospital6_Train_Val = 'Data/BraTS2021'\n",
    "Hospital7_Train = 'Data/BraTS2020/TrainingData'\n",
    "Hospital7_Val = 'Data/BraTS2020/ValidationData'\n",
    "Hospital8_Train_Val = 'Data/BraTS2019/HGG'\n",
    "Hospital9_Train_Val = 'Data/BraTS2019/LGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: TorchIO Preprocessing Transform\n",
    "\n",
    "transform = tio.Compose([\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),  # Normalize intensities to [0, 1]\n",
    "    tio.Resize((128, 128, 128)),               # Resize to fixed shape\n",
    "    tio.ZNormalization()                       # Normalize mean=0, std=1\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_transform = tio.Compose([\n",
    "    # Intensity-based\n",
    "    tio.RandomBiasField(p=0.3),\n",
    "    tio.RandomGamma(p=0.3),\n",
    "    tio.RandomNoise(p=0.2),\n",
    "    \n",
    "    # Spatial-based\n",
    "    tio.RandomAffine(\n",
    "        scales=(0.9, 1.1),\n",
    "        degrees=10,\n",
    "        translation=5,\n",
    "        center='image',\n",
    "        p=0.5\n",
    "    ),\n",
    "    tio.RandomElasticDeformation(p=0.2),\n",
    "    tio.RandomFlip(axes=('LR',), p=0.5),\n",
    "\n",
    "    # Preprocessing\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "    tio.Resize((128, 128, 128)),\n",
    "    tio.ZNormalization()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aff78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Client Dataset Paths and Loaders\n",
    "\n",
    "# Define paths (adjust as needed to match your directory structure)\n",
    "Hospital1_Train = 'Data/2023GLI/TrainingData'\n",
    "Hospital1_Val   = 'Data/2023GLI/ValidationData'\n",
    "Hospital2_Train = 'Data/2023MEN/TrainingData'\n",
    "Hospital2_Val   = 'Data/2023MEN/ValidationData'\n",
    "Hospital3_Train = 'Data/2023MET/TrainingData'\n",
    "Hospital3_Val   = 'Data/2023MET/ValidationData'\n",
    "Hospital4_Train = 'Data/2023PED/TrainingData'\n",
    "Hospital4_Val   = 'Data/2023PED/ValidationData'\n",
    "Hospital5_Train = 'Data/2023SSA/TrainingData'\n",
    "Hospital5_Val   = 'Data/2023SSA/ValidationData'\n",
    "Hospital6_Train_Val = 'Data/BraTS2021'\n",
    "Hospital7_Train = 'Data/BraTS2020/TrainingData'\n",
    "Hospital7_Val   = 'Data/BraTS2020/ValidationData'\n",
    "Hospital8_Train_Val = 'Data/BraTS2019/HGG'\n",
    "Hospital9_Train_Val = 'Data/BraTS2019/LGG'\n",
    "\n",
    "hospitals = {\n",
    "    \"Hospital1\": {\"train\": Hospital1_Train, \"val\": Hospital1_Val},\n",
    "    \"Hospital2\": {\"train\": Hospital2_Train, \"val\": Hospital2_Val},\n",
    "    \"Hospital3\": {\"train\": Hospital3_Train, \"val\": Hospital3_Val},\n",
    "    \"Hospital4\": {\"train\": Hospital4_Train, \"val\": Hospital4_Val},\n",
    "    \"Hospital5\": {\"train\": Hospital5_Train, \"val\": Hospital5_Val},\n",
    "    \"Hospital6\": {\"combined\": Hospital6_Train_Val},\n",
    "    \"Hospital7\": {\"train\": Hospital7_Train, \"val\": Hospital7_Val},\n",
    "    \"Hospital8\": {\"combined\": Hospital8_Train_Val},\n",
    "    \"Hospital9\": {\"combined\": Hospital9_Train_Val}\n",
    "}\n",
    "\n",
    "hospital_loaders = {}\n",
    "train_ratio = 0.8\n",
    "batch_size = 8\n",
    "\n",
    "for hospital, paths in hospitals.items():\n",
    "    print(f\"üîÅ Loading {hospital}...\")\n",
    "\n",
    "    if \"combined\" in paths:\n",
    "        #full_dataset = BraTSDataset(paths[\"combined\"], transform=transform, train=True)\n",
    "        full_dataset = BraTSDataset(paths[\"combined\"], transform=augment_transform, train=True)\n",
    "        train_size = int(train_ratio * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_set, val_set = random_split(full_dataset, [train_size, val_size])\n",
    "    else:\n",
    "        # train_set = BraTSDataset(paths[\"train\"], transform=transform, train=True)\n",
    "        # val_set = BraTSDataset(paths[\"val\"], transform=transform, train=False)\n",
    "\n",
    "        train_set = BraTSDataset(paths[\"train\"], transform=augment_transform, train=True)\n",
    "        val_set = BraTSDataset(paths[\"val\"], transform=transform, train=False)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    hospital_loaders[hospital] = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader\n",
    "    }\n",
    "\n",
    "print(\"\\n‚úÖ All hospital loaders are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Visualize Sample Volume + Mask Slice\n",
    "\n",
    "import random\n",
    "\n",
    "def visualize_random_sample(hospital=\"Hospital1\", slice_idx=64):\n",
    "    loader = hospital_loaders[hospital][\"train\"]\n",
    "    image, label = next(iter(loader))\n",
    "\n",
    "    print(f\"Input shape: {image.shape} | Label shape: {label.shape}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show slice from FLAIR (assume channel 3)\n",
    "    axs[0].imshow(image[0, 3, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    axs[0].set_title(f\"{hospital} - FLAIR slice {slice_idx}\")\n",
    "\n",
    "    # Corresponding segmentation mask slice\n",
    "    axs[1].imshow(label[0, 0, :, :, slice_idx].cpu(), cmap='Reds')\n",
    "    axs[1].set_title(f\"{hospital} - Segmentation slice {slice_idx}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example call\n",
    "visualize_random_sample(\"Hospital1\", slice_idx=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def visualize_two_samples_safe(hospital_name, slice_idx=64):\n",
    "    print(f\"\\nüîç Visualizing samples from {hospital_name}\")\n",
    "    loader = hospital_loaders[hospital_name][\"train\"]\n",
    "    samples = list(loader)\n",
    "\n",
    "    for i in range(min(2, len(samples))):\n",
    "        image, label = samples[i]\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axs[0].imshow(image[0, 3, :, :, slice_idx].cpu(), cmap='gray')\n",
    "        axs[0].set_title(f\"{hospital_name} - Patient {i+1} - FLAIR\")\n",
    "\n",
    "        axs[1].imshow(label[0, 0, :, :, slice_idx].cpu(), cmap='Reds')\n",
    "        axs[1].set_title(f\"{hospital_name} - Patient {i+1} - Mask\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Manually clear memory\n",
    "        del image, label\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6df417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_two_samples_safe(\"Hospital1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Dataset sizes per hospital:\")\n",
    "for hospital, loaders in hospital_loaders.items():\n",
    "    train_size = len(loaders['train'].dataset)\n",
    "    val_size = len(loaders['val'].dataset)\n",
    "    print(f\"{hospital} ‚Üí Train: {train_size} | Val: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6821c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Fixed TwinSegNet Model (ViT + UNet Hybrid)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock(out_channels + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        # Resize skip connection if needed\n",
    "        if x.shape[2:] != skip.shape[2:]:\n",
    "            skip = F.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        x = torch.cat((x, skip), dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class PatchEmbedViT(nn.Module):\n",
    "    def __init__(self, in_channels=128, embed_dim=256, patch_size=2):\n",
    "        super(PatchEmbedViT, self).__init__()\n",
    "        self.patch_embed = nn.Conv3d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, embed_dim, 1, 1, 1))  # minimal shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if x.shape[2:] != self.pos_embed.shape[2:]:\n",
    "            pos_embed = F.interpolate(self.pos_embed, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        else:\n",
    "            pos_embed = self.pos_embed\n",
    "        return x + pos_embed\n",
    "\n",
    "\n",
    "class TwinSegNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_classes=3, base_channels=32):\n",
    "        super(TwinSegNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(in_channels, base_channels)              # 128\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.enc2 = ConvBlock(base_channels, base_channels * 2)        # 64\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.enc3 = ConvBlock(base_channels * 2, base_channels * 4)    # 32\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.enc4 = ConvBlock(base_channels * 4, base_channels * 8)    # 16\n",
    "        self.pool4 = nn.MaxPool3d(2)\n",
    "\n",
    "        # ViT at bottleneck\n",
    "        self.vit = PatchEmbedViT(in_channels=base_channels * 8, embed_dim=base_channels * 16, patch_size=2)\n",
    "        self.vit_proj = nn.Conv3d(base_channels * 16, base_channels * 8, kernel_size=1)\n",
    "\n",
    "        # Decoder (UNet-style)\n",
    "        self.up4 = UpBlock(base_channels * 8, base_channels * 4, base_channels * 4)  # match enc3\n",
    "        self.up3 = UpBlock(base_channels * 4, base_channels * 2, base_channels * 2)  # match enc2\n",
    "        self.up2 = UpBlock(base_channels * 2, base_channels, base_channels)          # match enc1\n",
    "        self.final_conv = nn.Conv3d(base_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)                # [B, 32, 128,128,128]\n",
    "        e2 = self.enc2(self.pool1(e1))   # [B, 64, 64,64,64]\n",
    "        e3 = self.enc3(self.pool2(e2))   # [B, 128, 32,32,32]\n",
    "        e4 = self.enc4(self.pool3(e3))   # [B, 256, 16,16,16]\n",
    "        b = self.pool4(e4)               # [B, 256, 8,8,8]\n",
    "\n",
    "        b = self.vit(b)                  # [B, 512, 4,4,4] ‚Üí [B, 256, 4,4,4]\n",
    "        b = self.vit_proj(b)             # [B, 256, 4,4,4]\n",
    "\n",
    "        d4 = self.up4(b, e3)             # [B, 128, 8,8,8]\n",
    "        d3 = self.up3(d4, e2)            # [B, 64, 16,16,16]\n",
    "        d2 = self.up2(d3, e1)            # [B, 32, 32,32,32]\n",
    "        out = self.final_conv(d2)        # [B, n_classes, 32,32,32]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    pred: (B, C, D, H, W)\n",
    "    target: (B, 1, D', H', W') ‚Üí label mask\n",
    "    \"\"\"\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "    # Resize target to match pred spatial shape\n",
    "    if target.shape[2:] != pred.shape[2:]:\n",
    "        target = F.interpolate(target.float(), size=pred.shape[2:], mode='nearest')\n",
    "\n",
    "    # One-hot encode\n",
    "    target = target.squeeze(1).long()  # (B, D, H, W)\n",
    "    target = F.one_hot(target, num_classes=pred.shape[1])  # (B, D, H, W, C)\n",
    "    target = target.permute(0, 4, 1, 2, 3).float()          # (B, C, D, H, W)\n",
    "\n",
    "    # Dice computation\n",
    "    intersection = (pred * target).sum(dim=(2, 3, 4))\n",
    "    union = pred.sum(dim=(2, 3, 4)) + target.sum(dim=(2, 3, 4))\n",
    "    dice = (2 * intersection + epsilon) / (union + epsilon)\n",
    "\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "\n",
    "def dice_coefficient(pred, target, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Computes Dice coefficient for evaluation (not differentiable).\n",
    "    Assumes pred is logits and target is class index (not one-hot).\n",
    "    \"\"\"\n",
    "    pred = torch.argmax(torch.softmax(pred, dim=1), dim=1)\n",
    "    target = target.squeeze(1).long()\n",
    "\n",
    "    dice_scores = []\n",
    "    for class_id in range(1, pred.shape[1] if pred.ndim == 5 else 2):  # skip background\n",
    "        pred_class = (pred == class_id).float()\n",
    "        target_class = (target == class_id).float()\n",
    "\n",
    "        intersection = (pred_class * target_class).sum()\n",
    "        union = pred_class.sum() + target_class.sum()\n",
    "\n",
    "        dice = (2 * intersection + epsilon) / (union + epsilon)\n",
    "        dice_scores.append(dice.item())\n",
    "\n",
    "    return np.mean(dice_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL X: Improved Local Trainer with Logging\n",
    "\n",
    "def train_one_client(model, dataloader, optimizer, epochs=1, client_name=\"\"):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        print(f\"\\nüöÄ [{client_name}] Epoch {epoch+1}/{epochs} ‚Äî Training {len(dataloader)} patients\")\n",
    "\n",
    "        for i, (images, masks) in enumerate(dataloader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = dice_loss(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            epoch_loss += batch_loss\n",
    "\n",
    "            print(f\"   üì¶ Batch {i+1}/{len(dataloader)} ‚Äî Loss: {batch_loss:.4f}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        total_loss += avg_loss\n",
    "        print(f\"‚úÖ [{client_name}] Epoch {epoch+1} Complete ‚Äî Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model.state_dict()  # return updated weights for FedAvg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ac31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwinSegNet(in_channels=4, n_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "client_name = \"Hospital1\"\n",
    "client_loader = hospital_loaders[client_name][\"train\"]\n",
    "\n",
    "new_weights = train_one_client(model, client_loader, optimizer, epochs=2, client_name=client_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4403061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fe853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
