{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd53492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# SECTION 1: SETUP & IMPORTS\n",
    "\n",
    "# Core ML\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "import warnings\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "\n",
    "# System and Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c7ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "IMG_SIZE = 128\n",
    "VOLUME_SLICES = 50\n",
    "VOLUME_START_AT = 22\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 5\n",
    "NUM_ROUNDS = 10\n",
    "batch_size = 1  # stable\n",
    "pin_memory = True\n",
    "num_workers = 4  # or os.cpu_count() // 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.patient_dirs = sorted(os.listdir(root_dir))\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_dirs[idx]\n",
    "        patient_path = os.path.join(self.root_dir, patient_id)\n",
    "\n",
    "        # Load MRI modalities\n",
    "        modalities = ['t1c', 't1n', 't2f', 't2w']\n",
    "        image_data = []\n",
    "        for mod in modalities:\n",
    "            image_path = os.path.join(patient_path, f\"{patient_id}-{mod}.nii\")\n",
    "            image = nib.load(image_path).get_fdata()\n",
    "            image_data.append(image)\n",
    "\n",
    "        image_np = np.stack(image_data, axis=0).astype(np.float32)\n",
    "        image_tensor = torch.tensor(image_np, dtype=torch.float32)\n",
    "\n",
    "        label_path = os.path.join(patient_path, f\"{patient_id}-seg.nii\")\n",
    "        label_np = nib.load(label_path).get_fdata().astype(np.uint8)\n",
    "        label_np[label_np == 4] = 3  # Map 4‚Üí3 to maintain 4-class system\n",
    "        label_tensor = torch.from_numpy(label_np).long().unsqueeze(0)\n",
    "    \n",
    "        # Apply TorchIO transform\n",
    "        if self.transform:\n",
    "            subject_dict = {\"images\": tio.ScalarImage(tensor=image_tensor)}\n",
    "            if label_tensor is not None:\n",
    "                subject_dict[\"label\"] = tio.LabelMap(tensor=label_tensor)\n",
    "            subject = tio.Subject(**subject_dict)\n",
    "            transformed = self.transform(subject)\n",
    "            image_tensor = transformed.images.data\n",
    "            if label_tensor is not None:\n",
    "                label_tensor = transformed.label.data\n",
    "\n",
    "        return (image_tensor, label_tensor) if self.train else image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739a3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: TorchIO Preprocessing Transform\n",
    "\n",
    "transform = tio.Compose([\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),  # Normalize intensities to [0, 1]\n",
    "    tio.Resize((128, 128, 128)),               # Resize to fixed shape\n",
    "    tio.ZNormalization()                       # Normalize mean=0, std=1\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_transform = tio.Compose([\n",
    "    # Intensity-based\n",
    "    tio.RandomBiasField(p=0.3),\n",
    "    tio.RandomGamma(p=0.3),\n",
    "    tio.RandomNoise(p=0.2),\n",
    "    \n",
    "    # Spatial-based\n",
    "    tio.RandomAffine(\n",
    "        scales=(0.9, 1.1),\n",
    "        degrees=10,\n",
    "        translation=5,\n",
    "        center='image',\n",
    "        p=0.5\n",
    "    ),\n",
    "    tio.RandomElasticDeformation(p=0.2),\n",
    "    tio.RandomFlip(axes=('LR',), p=0.5),\n",
    "\n",
    "    # Preprocessing\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "    tio.Resize((128, 128, 128)),\n",
    "    tio.ZNormalization()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aff78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Client Dataset Paths and Loaders\n",
    "\n",
    "# Define paths (adjust as needed to match your directory structure)\n",
    "Hospital1_Train = 'Data/2023GLI/TrainingData'\n",
    "Hospital1_Val   = 'Data/2023GLI/ValidationData'\n",
    "Hospital2_Train = 'Data/2023MEN/TrainingData'\n",
    "Hospital2_Val   = 'Data/2023MEN/ValidationData'\n",
    "Hospital3_Train = 'Data/2023MET/TrainingData'\n",
    "Hospital3_Val   = 'Data/2023MET/ValidationData'\n",
    "Hospital4_Train = 'Data/2023PED/TrainingData'\n",
    "Hospital4_Val   = 'Data/2023PED/ValidationData'\n",
    "Hospital5_Train = 'Data/2023SSA/TrainingData'\n",
    "Hospital5_Val   = 'Data/2023SSA/ValidationData'\n",
    "Hospital6_Train_Val = 'Data/BraTS2021'\n",
    "Hospital7_Train = 'Data/BraTS2020/TrainingData'\n",
    "Hospital7_Val   = 'Data/BraTS2020/ValidationData'\n",
    "Hospital8_Train_Val = 'Data/BraTS2019/HGG'\n",
    "Hospital9_Train_Val = 'Data/BraTS2019/LGG'\n",
    "\n",
    "hospitals = {\n",
    "    \"Hospital1\": {\"combined\": Hospital1_Train},\n",
    "    \"Hospital2\": {\"combined\": Hospital2_Train},\n",
    "    \"Hospital3\": {\"combined\": Hospital3_Train},\n",
    "    \"Hospital4\": {\"combined\": Hospital4_Train},\n",
    "    \"Hospital5\": {\"combined\": Hospital5_Train},\n",
    "    \"Hospital6\": {\"combined\": Hospital6_Train_Val},\n",
    "    \"Hospital7\": {\"combined\": Hospital7_Train},\n",
    "    \"Hospital8\": {\"combined\": Hospital8_Train_Val},\n",
    "    \"Hospital9\": {\"combined\": Hospital9_Train_Val}\n",
    "}\n",
    "\n",
    "hospital_loaders = {}\n",
    "train_ratio = 0.8\n",
    "batch_size = 1\n",
    "\n",
    "for hospital, paths in hospitals.items():\n",
    "    print(f\"üîÅ Loading {hospital}...\")\n",
    "\n",
    "    if \"combined\" in paths or hospital in [\"Hospital1\", \"Hospital2\", \"Hospital3\", \"Hospital4\", \"Hospital5\", \"Hospital7\"]:\n",
    "        # Random split from TrainingData\n",
    "        dataset_path = paths[\"combined\"]\n",
    "\n",
    "        full_dataset = BraTSDataset(dataset_path, transform=transform, train=True)\n",
    "        train_size = int(train_ratio * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_set, val_set = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    hospital_loaders[hospital] = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ All hospital loaders are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Visualize Sample Volume + Mask Slice\n",
    "\n",
    "import random\n",
    "\n",
    "def visualize_random_sample(hospital=\"Hospital1\", slice_idx=64):\n",
    "    loader = hospital_loaders[hospital][\"val\"]\n",
    "    image, label = next(iter(loader))\n",
    "\n",
    "    print(f\"Input shape: {image.shape} | Label shape: {label.shape}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show slice from FLAIR (assume channel 3)\n",
    "    axs[0].imshow(image[0, 3, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    axs[0].set_title(f\"{hospital} - FLAIR slice {slice_idx}\")\n",
    "\n",
    "    # Corresponding segmentation mask slice\n",
    "    axs[1].imshow(label[0, 0, :, :, slice_idx].cpu(), cmap='Reds')\n",
    "    axs[1].set_title(f\"{hospital} - Segmentation slice {slice_idx}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example call\n",
    "visualize_random_sample(\"Hospital1\", slice_idx=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Dataset sizes per hospital:\")\n",
    "for hospital, loaders in hospital_loaders.items():\n",
    "    train_size = len(loaders['train'].dataset)\n",
    "    val_size = len(loaders['val'].dataset)\n",
    "    print(f\"{hospital} ‚Üí Train: {train_size} | Val: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6821c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Fixed TwinSegNet Model (ViT + UNet Hybrid)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock(out_channels + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        # Resize skip connection if needed\n",
    "        if x.shape[2:] != skip.shape[2:]:\n",
    "            skip = F.interpolate(skip, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        x = torch.cat((x, skip), dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class PatchEmbedViT(nn.Module):\n",
    "    def __init__(self, in_channels=128, embed_dim=256, patch_size=2):\n",
    "        super(PatchEmbedViT, self).__init__()\n",
    "        self.patch_embed = nn.Conv3d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, embed_dim, 1, 1, 1))  # minimal shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if x.shape[2:] != self.pos_embed.shape[2:]:\n",
    "            pos_embed = F.interpolate(self.pos_embed, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        else:\n",
    "            pos_embed = self.pos_embed\n",
    "        return x + pos_embed\n",
    "\n",
    "\n",
    "class TwinSegNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_classes=3, base_channels=32):\n",
    "        super(TwinSegNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(in_channels, base_channels)              # 128\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.enc2 = ConvBlock(base_channels, base_channels * 2)        # 64\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.enc3 = ConvBlock(base_channels * 2, base_channels * 4)    # 32\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.enc4 = ConvBlock(base_channels * 4, base_channels * 8)    # 16\n",
    "        self.pool4 = nn.MaxPool3d(2)\n",
    "\n",
    "        # ViT at bottleneck\n",
    "        self.vit = PatchEmbedViT(in_channels=base_channels * 8, embed_dim=base_channels * 16, patch_size=2)\n",
    "        self.vit_proj = nn.Conv3d(base_channels * 16, base_channels * 8, kernel_size=1)\n",
    "\n",
    "        # Decoder (UNet-style)\n",
    "        self.up4 = UpBlock(base_channels * 8, base_channels * 4, base_channels * 4)  # match enc3\n",
    "        self.up3 = UpBlock(base_channels * 4, base_channels * 2, base_channels * 2)  # match enc2\n",
    "        self.up2 = UpBlock(base_channels * 2, base_channels, base_channels)          # match enc1\n",
    "        self.final_conv = nn.Conv3d(base_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)                # [B, 32, 128,128,128]\n",
    "        e2 = self.enc2(self.pool1(e1))   # [B, 64, 64,64,64]\n",
    "        e3 = self.enc3(self.pool2(e2))   # [B, 128, 32,32,32]\n",
    "        e4 = self.enc4(self.pool3(e3))   # [B, 256, 16,16,16]\n",
    "        b = self.pool4(e4)               # [B, 256, 8,8,8]\n",
    "\n",
    "        b = self.vit(b)                  # [B, 512, 4,4,4] ‚Üí [B, 256, 4,4,4]\n",
    "        b = self.vit_proj(b)             # [B, 256, 4,4,4]\n",
    "\n",
    "        d4 = self.up4(b, e3)             # [B, 128, 8,8,8]\n",
    "        d3 = self.up3(d4, e2)            # [B, 64, 16,16,16]\n",
    "        d2 = self.up2(d3, e1)            # [B, 32, 32,32,32]\n",
    "        out = self.final_conv(d2)        # [B, n_classes, 32,32,32]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    pred: (B, C, D, H, W)\n",
    "    target: (B, 1, D', H', W') ‚Üí label mask\n",
    "    \"\"\"\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "    # Resize target to match pred spatial shape\n",
    "    if target.shape[2:] != pred.shape[2:]:\n",
    "        target = F.interpolate(target.float(), size=pred.shape[2:], mode='nearest')\n",
    "\n",
    "    # One-hot encode\n",
    "    target = target.squeeze(1).long()  # (B, D, H, W)\n",
    "    target = F.one_hot(target, num_classes=pred.shape[1])  # (B, D, H, W, C)\n",
    "    target = target.permute(0, 4, 1, 2, 3).float()          # (B, C, D, H, W)\n",
    "\n",
    "    # Dice computation\n",
    "    intersection = (pred * target).sum(dim=(2, 3, 4))\n",
    "    union = pred.sum(dim=(2, 3, 4)) + target.sum(dim=(2, 3, 4))\n",
    "    dice = (2 * intersection + epsilon) / (union + epsilon)\n",
    "\n",
    "    return 1 - dice.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc197e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def clear_cuda():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print(f\"üßπ GPU memory cleared. Available: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!fuser -v /dev/nvidia0  # see PIDs using the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 <3013>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b68de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_devices = {\n",
    "    \"Hospital1\": \"cuda:1\",\n",
    "    \"Hospital2\": \"cuda:1\",\n",
    "    \"Hospital3\": \"cuda:1\",\n",
    "    \"Hospital4\": \"cuda:1\",\n",
    "    \"Hospital5\": \"cuda:1\",\n",
    "    \"Hospital6\": \"cuda:1\",\n",
    "    \"Hospital7\": \"cuda:1\",\n",
    "    \"Hospital8\": \"cuda:1\",\n",
    "    \"Hospital9\": \"cuda:1\",\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    dices = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Make sure masks and preds have same spatial size\n",
    "            if masks.shape[2:] != preds.shape[1:]:\n",
    "                masks = F.interpolate(masks.float(), size=preds.shape[1:], mode='nearest').long()\n",
    "\n",
    "            masks = masks.squeeze(1)  # (B, D, H, W)\n",
    "            preds = preds.squeeze(1)  # (B, D, H, W)\n",
    "\n",
    "            # Calculate Dice only over foreground\n",
    "            intersection = ((preds == masks) & (masks > 0)).float().sum()\n",
    "            union = ((preds > 0).float() + (masks > 0).float()).sum()\n",
    "\n",
    "            dice_score = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "            dices.append(dice_score.item())\n",
    "\n",
    "    if len(dices) == 0:\n",
    "        print(\"‚ö†Ô∏è No valid batches evaluated.\")\n",
    "        return 0.0\n",
    "\n",
    "    avg_dice = np.mean(dices)\n",
    "    return avg_dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ed945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_one_client(model, dataloader, optimizer, epochs=1, client_name=\"\", device=\"cuda\"):\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "#     total_loss = 0\n",
    "\n",
    "#     scaler = GradScaler()\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         epoch_loss = 0\n",
    "#         print(f\"\\nüöÄ [{client_name}] Epoch {epoch+1}/{epochs} ‚Äî Training {len(dataloader)} batches\")\n",
    "\n",
    "#         for i, (images, masks) in enumerate(dataloader):\n",
    "#             images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             with autocast():\n",
    "#                 outputs = model(images)\n",
    "#                 loss = dice_loss(outputs, masks)\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "#             print(f\"   üì¶ Batch {i+1}/{len(dataloader)} ‚Äî Loss: {loss.item():.4f} ‚Äî \"\n",
    "#                   f\"Mem: {torch.cuda.memory_allocated(device) / 1e6:.1f} MB\")\n",
    "\n",
    "#             epoch_loss += loss.item()\n",
    "\n",
    "#         avg_loss = epoch_loss / len(dataloader)\n",
    "#         total_loss += avg_loss\n",
    "\n",
    "#         # üß™ Evaluate after each epoch\n",
    "#         val_loader = hospital_loaders[client_name][\"val\"]\n",
    "#         dice = evaluate_model(model, val_loader, device)\n",
    "\n",
    "#         print(f\"‚úÖ [{client_name}] Epoch {epoch+1} Complete ‚Äî Avg Loss: {avg_loss:.4f} | Val Dice: {dice:.4f}\")\n",
    "\n",
    "#     return model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64352bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_one_client(model, dataloader, optimizer, epochs=1, client_name=\"\", device=\"cuda\"):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        print(f\"\\nüöÄ [{client_name}] Epoch {epoch+1}/{epochs} ‚Äî Training {len(dataloader)} batches\")\n",
    "\n",
    "        for i, (images, masks) in enumerate(dataloader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = dice_loss(outputs, masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            print(f\"   üì¶ Batch {i+1}/{len(dataloader)} ‚Äî Loss: {loss.item():.4f} ‚Äî \"\n",
    "                  f\"Mem: {torch.cuda.memory_allocated(device) / 1e6:.1f} MB\")\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        total_loss += avg_loss\n",
    "        print(f\"‚úÖ [{client_name}] Epoch {epoch+1} Complete ‚Äî Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ac31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clients_round(client_names, hospital_loaders, base_model_fn, epochs=1, lr=1e-4):\n",
    "    updated_weights = {}\n",
    "    for client in client_names:\n",
    "        device = client_devices[client]\n",
    "        print(f\"üî• Training {client} on {device}\")\n",
    "\n",
    "        model = base_model_fn().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        train_loader = hospital_loaders[client][\"train\"]\n",
    "\n",
    "        weights = train_one_client(model, train_loader, optimizer,\n",
    "                                   epochs=epochs, client_name=client, device=device)\n",
    "        updated_weights[client] = weights\n",
    "    return updated_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f251d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Training Hospital1\n",
    "\n",
    "client_name = \"Hospital3\"\n",
    "device = client_devices[client_name]\n",
    "\n",
    "model = TwinSegNet(in_channels=4, n_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_loader = hospital_loaders[client_name][\"train\"]\n",
    "\n",
    "# üîÅ Call the training function\n",
    "new_weights = train_one_client(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    client_name=client_name,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4403061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This trains all specified clients in one FL round\n",
    "clients_to_train = [\"Hospital1\", \"Hospital2\"]  # or more\n",
    "def build_model(): return TwinSegNet(in_channels=4, n_classes=4)\n",
    "\n",
    "client_weights = train_clients_round(\n",
    "    client_names=clients_to_train,\n",
    "    hospital_loaders=hospital_loaders,\n",
    "    base_model_fn=build_model,\n",
    "    epochs=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(client_weights):\n",
    "    \"\"\"\n",
    "    client_weights: dict of {client_name: state_dict}\n",
    "    returns: averaged global model weights\n",
    "    \"\"\"\n",
    "    global_model = {}\n",
    "\n",
    "    for k in next(iter(client_weights.values())).keys():\n",
    "        global_model[k] = torch.stack([weights[k].float() for weights in client_weights.values()], dim=0).mean(dim=0)\n",
    "\n",
    "    return global_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training all clients\n",
    "global_weights = fed_avg(client_weights)\n",
    "\n",
    "# To load global model:\n",
    "model.load_state_dict(global_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_training_rounds(\n",
    "    client_names, \n",
    "    hospital_loaders, \n",
    "    base_model_fn, \n",
    "    num_rounds=2, \n",
    "    local_epochs=1, \n",
    "    lr=1e-4,\n",
    "    device_mapping=None\n",
    "):\n",
    "    \"\"\"\n",
    "    client_names: list of client IDs\n",
    "    hospital_loaders: dictionary of data loaders\n",
    "    base_model_fn: function to instantiate model\n",
    "    num_rounds: number of FL rounds\n",
    "    local_epochs: number of epochs at each client per round\n",
    "    lr: learning rate\n",
    "    device_mapping: client_name ‚Üí device\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize global model\n",
    "    global_model = base_model_fn()\n",
    "    global_weights = global_model.state_dict()\n",
    "\n",
    "    history = {\"round\": [], \"global_val_dice\": []}\n",
    "\n",
    "    for rnd in range(1, num_rounds + 1):\n",
    "        print(f\"\\nüåç Federated Round {rnd}/{num_rounds}\")\n",
    "\n",
    "        client_weights = {}\n",
    "\n",
    "        # Local training for each client\n",
    "        for client in client_names:\n",
    "            print(f\"\\nüîπ Training Client: {client}\")\n",
    "            device = device_mapping.get(client, \"cuda:0\")\n",
    "\n",
    "            model = base_model_fn().to(device)\n",
    "            model.load_state_dict(global_weights)  # Start from global model\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            train_loader = hospital_loaders[client][\"train\"]\n",
    "\n",
    "            # Train locally\n",
    "            new_weights = train_one_client(\n",
    "                model, train_loader, optimizer,\n",
    "                epochs=local_epochs,\n",
    "                client_name=client,\n",
    "                device=device\n",
    "            )\n",
    "            client_weights[client] = new_weights\n",
    "\n",
    "        # üîÄ Aggregate weights (FedAvg)\n",
    "        global_weights = fed_avg(client_weights)\n",
    "\n",
    "        # ‚úÖ Evaluate global model\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        dice_scores = []\n",
    "\n",
    "        for client in client_names:\n",
    "            device = device_mapping.get(client, \"cuda:0\")\n",
    "            val_loader = hospital_loaders[client][\"val\"]\n",
    "            dice = evaluate_model(global_model.to(device), val_loader, device=device)\n",
    "            dice_scores.append(dice)\n",
    "            print(f\"üìà Validation Dice on {client}: {dice:.4f}\")\n",
    "\n",
    "        avg_dice = np.mean(dice_scores)\n",
    "        history[\"round\"].append(rnd)\n",
    "        history[\"global_val_dice\"].append(avg_dice)\n",
    "\n",
    "        print(f\"\\nüåü Round {rnd} Complete ‚Äî Global Avg Validation Dice: {avg_dice:.4f}\")\n",
    "\n",
    "    return global_weights, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_to_train = [\"Hospital1\", \"Hospital2\", \"Hospital3\", \"Hospital4\", \"Hospital5\", \"Hospital6\", \"Hospital7\", \"Hospital8\", \"Hospital9\"]\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    return TwinSegNet(in_channels=4, n_classes=4)\n",
    "\n",
    "# Run federated learning!\n",
    "final_weights, training_history = federated_training_rounds(\n",
    "    client_names=clients_to_train,\n",
    "    hospital_loaders=hospital_loaders,\n",
    "    base_model_fn=build_model,\n",
    "    num_rounds=10,            # üî• 5 global rounds\n",
    "    local_epochs=5,          # üî• 2 local epochs per client\n",
    "    lr=1e-4,\n",
    "    device_mapping=client_devices\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_progress(history):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history[\"round\"], history[\"global_val_dice\"], marker='o')\n",
    "    plt.title(\"Global Average Dice Score per Federated Round\")\n",
    "    plt.xlabel(\"Federated Round\")\n",
    "    plt.ylabel(\"Average Dice Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# After training\n",
    "plot_training_progress(training_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69f516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
