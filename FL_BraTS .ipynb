{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cd53492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "import flwr as fl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c7ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "IMG_SIZE = 128\n",
    "VOLUME_SLICES = 50\n",
    "VOLUME_START_AT = 22\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 5\n",
    "NUM_ROUNDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24ed6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "images_path = \"Data/BraTS2021\"\n",
    "\n",
    "# Load all patients\n",
    "all_patients = [os.path.join(images_path, p) for p in os.listdir(images_path) if not p.startswith(\".\")]\n",
    "np.random.shuffle(all_patients)\n",
    "\n",
    "# Split dataset across hospitals\n",
    "datasets = {\n",
    "    \"1\": all_patients[:len(all_patients)//3],\n",
    "    \"2\": all_patients[len(all_patients)//3:2*len(all_patients)//3],\n",
    "    \"3\": all_patients[2*len(all_patients)//3:]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9aff78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Define Data Generator\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, batch_size=1, dim=(IMG_SIZE, IMG_SIZE), n_channels=2, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        X = np.zeros((self.batch_size * VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size * VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(images_path, os.path.basename(i), os.path.basename(i))\n",
    "            try:\n",
    "                flair = nib.load(f'{case_path}_flair.nii').get_fdata()\n",
    "                ce = nib.load(f'{case_path}_t1ce.nii').get_fdata()\n",
    "                seg = nib.load(f'{case_path}_seg.nii').get_fdata()\n",
    "\n",
    "                for j in range(VOLUME_SLICES):\n",
    "                    X[j + VOLUME_SLICES * c, :, :, 0] = cv2.resize(flair[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                    X[j + VOLUME_SLICES * c, :, :, 1] = cv2.resize(ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                    y[j + VOLUME_SLICES * c] = cv2.resize(seg[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                y[y == 4] = 3  # Adjust class values\n",
    "                mask = tf.one_hot(y, 4)\n",
    "                Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "                return X / np.max(X), Y\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {case_path}: {e}\")\n",
    "                return np.zeros_like(X), np.zeros_like(Y)\n",
    "\n",
    "# Assign DataGenerators to Federated Clients\n",
    "hospital_generators = {\n",
    "    \"1\": DataGenerator(datasets[\"1\"], batch_size=BATCH_SIZE),\n",
    "    \"2\": DataGenerator(datasets[\"2\"], batch_size=BATCH_SIZE),\n",
    "    \"3\": DataGenerator(datasets[\"3\"], batch_size=BATCH_SIZE),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset loading is working correctly for Hospital 1\n",
    "x_batch, y_batch = hospital_generators[\"1\"].__getitem__(0)\n",
    "\n",
    "print(\"Dataset Loading Verification:\")\n",
    "print(f\"Input MRI Shape: {x_batch.shape}\")\n",
    "print(f\"Segmentation Mask Shape: {y_batch.shape}\")\n",
    "print(f\"Max Intensity Value in Input: {np.max(x_batch)}\")\n",
    "print(f\"Unique Labels in Segmentation: {np.unique(y_batch)}\")\n",
    "\n",
    "# Visualize one MRI slice and its corresponding segmentation mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_batch[0, :, :, 0], cmap=\"gray\")\n",
    "plt.title(\"FLAIR MRI Slice\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.argmax(y_batch[0], axis=-1), cmap=\"jet\")  # Convert one-hot to categorical\n",
    "plt.title(\"Ground Truth Segmentation Mask\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17351348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unet_model(input_shape=(128, 128, 2)):  \n",
    "    inputs = layers.Input(input_shape)\n",
    "    conv1 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(pool2)\n",
    "\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(up1)\n",
    "    up1 = layers.Concatenate()([conv2, up1])\n",
    "\n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(up1)\n",
    "    up2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(up2)\n",
    "    up2 = layers.Concatenate()([conv1, up2])\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\", padding=\"same\")(up2)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70e45f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, train_generator, test_generator):\n",
    "        self.model = model\n",
    "        self.train_generator = train_generator\n",
    "        self.test_generator = test_generator\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        \n",
    "        print(f\"\\nðŸ¥ [FL Client] Training Model for Hospital...\\n\")\n",
    "        \n",
    "        history = self.model.fit(self.train_generator, epochs=1, verbose=1)\n",
    "        \n",
    "        print(f\"âœ” [FL Training Done] Loss: {history.history['loss'][-1]:.4f}, Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "        \n",
    "        return self.model.get_weights(), len(self.train_generator), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, accuracy = self.model.evaluate(self.test_generator, verbose=0)\n",
    "        print(f\"ðŸ“Š [FL Evaluation] Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        return loss, len(self.test_generator), {\"accuracy\": accuracy}\n",
    "\n",
    "# Assign Clients\n",
    "hospital_clients = {\n",
    "    \"1\": HospitalClient(create_unet_model(), hospital_generators[\"1\"], hospital_generators[\"1\"]),\n",
    "    \"2\": HospitalClient(create_unet_model(), hospital_generators[\"2\"], hospital_generators[\"2\"]),\n",
    "    \"3\": HospitalClient(create_unet_model(), hospital_generators[\"3\"], hospital_generators[\"3\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66a832d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def start_server():\n",
    "    print(\"\\nðŸš€ [FL Server] Starting Federated Learning...\\n\")\n",
    "\n",
    "    def fit_round(server_round, parameters, config):\n",
    "        print(f\"\\nðŸ“¡ [FL Server] Received Model Update for Round {server_round}\\n\")\n",
    "        return parameters, {}\n",
    "\n",
    "    strategy = fl.server.strategy.FedAvg(on_fit_config_fn=fit_round)\n",
    "    \n",
    "    fl.server.start_server(config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS), strategy=strategy)\n",
    "    \n",
    "    print(\"\\nâœ… [FL Server] Training Completed!\")\n",
    "\n",
    "\n",
    "\n",
    "def start_client(hospital_id):\n",
    "    print(f\"\\nðŸš€ [Client {hospital_id}] Attempting to Connect to FL Server...\\n\")\n",
    "    \n",
    "    client = hospital_clients[hospital_id]\n",
    "    \n",
    "    print(f\"\\nâœ… [Client {hospital_id}] Successfully Started\\n\")\n",
    "    \n",
    "    fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=client)\n",
    "    \n",
    "    print(f\"\\nðŸ¥ [Client {hospital_id}] Finished Training!\\n\")\n",
    "\n",
    "\n",
    "# Run FL Training and Observe Output\n",
    "\n",
    "# Launch server and clients\n",
    "server_process = Process(target=start_server)\n",
    "server_process.start()\n",
    "\n",
    "client_processes = []\n",
    "p = Process(target=start_client, args=(\"1\",))  # Only run Client 1\n",
    "client_processes.append(p)\n",
    "p.start()\n",
    "\n",
    "p.join()  # Ensure the client finishes before moving to the next one\n",
    "\n",
    "server_process.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Dice Coefficient Metric\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# IoU Metric\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    total = K.sum(y_true) + K.sum(y_pred)\n",
    "    union = total - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Evaluate Model Performance Across Hospitals\n",
    "hospital_scores = {}\n",
    "for hospital_id in [\"1\", \"2\", \"3\"]:\n",
    "    print(f\"Evaluating Model for Hospital {hospital_id}...\")\n",
    "    \n",
    "    x_test, y_test = hospital_generators[hospital_id].__getitem__(0)\n",
    "    \n",
    "    y_pred = hospital_clients[hospital_id].model.predict(x_test)\n",
    "    dice = dice_coefficient(y_test, y_pred)\n",
    "    iou_score = iou(y_test, y_pred)\n",
    "    \n",
    "    hospital_scores[hospital_id] = {\"Dice\": K.eval(dice), \"IoU\": K.eval(iou_score)}\n",
    "\n",
    "print(\"\\nFederated Learning Model Performance Across Hospitals:\")\n",
    "for hospital, scores in hospital_scores.items():\n",
    "    print(f\"Hospital {hospital} -> Dice: {scores['Dice']:.4f}, IoU: {scores['IoU']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize segmentation outputs\n",
    "def visualize_segmentation(model, x_test, y_test, index=0):\n",
    "    prediction = model.predict(x_test[index:index+1])[0, :, :, 0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Input Image (FLAIR)\")\n",
    "    plt.imshow(x_test[index, :, :, 0], cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(y_test[index, :, :, 0], cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Segmentation\")\n",
    "    plt.imshow(prediction, cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Select a hospital and visualize segmentation\n",
    "x_test, y_test = next(iter(create_dataset(datasets[\"1\"])))\n",
    "visualize_segmentation(global_model, x_test, y_test, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e41a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Conv2D\n",
    "\n",
    "# Prepare tumor progression dataset\n",
    "def prepare_tumor_time_series(file_paths, time_steps=5):\n",
    "    sequences = []\n",
    "    for file_path in file_paths:\n",
    "        # Load segmented MRI slices\n",
    "        seg = nib.load(file_path + '_seg.nii').get_fdata()\n",
    "        seg = cv2.resize(seg, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Normalize & reshape\n",
    "        seg = seg / np.max(seg)\n",
    "        seq = [seg[:, :, i] for i in range(time_steps)]\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "# Prepare dataset for LSTM training\n",
    "X_tumor_train = prepare_tumor_time_series(datasets[\"1\"], time_steps=5)\n",
    "Y_tumor_train = X_tumor_train[:, 1:]  # Next MRI slice is target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM-based tumor growth predictor\n",
    "model_tumor = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(4, IMG_SIZE*IMG_SIZE)),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(IMG_SIZE*IMG_SIZE, activation=\"relu\"),  # Predict next MRI slice\n",
    "])\n",
    "\n",
    "model_tumor.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model_tumor.fit(X_tumor_train, Y_tumor_train, epochs=50, batch_size=4, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Next MRI Slice (Tumor Evolution)\n",
    "def predict_tumor_growth(model, x_test):\n",
    "    pred = model.predict(x_test)\n",
    "    return pred.reshape(IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "# Select a test patient\n",
    "x_tumor_test = X_tumor_train[0:1]\n",
    "predicted_tumor = predict_tumor_growth(model_tumor, x_tumor_test)\n",
    "\n",
    "# Visualize Tumor Evolution Prediction\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Current Tumor MRI Slice\")\n",
    "plt.imshow(x_tumor_test[0, -1], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Predicted Future Tumor Growth\")\n",
    "plt.imshow(predicted_tumor, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
